CHAINID=6546
# Working validator ENR - from mining validator at 144.76.98.242 (block 195+)
BOOTNODE="enr:-KO4QPC8XAim9XZTMQb-Yp5VGRC9ao5HsULBycMR67n3fa3IKzfqZLaAe8Ei9mzqK_Y7oFevRv3zURmHMgrQOWtLIkWGAZk7l2fMg2V0aMfGhODg-12AgmlkgnY0gmlwhJBMYvKJc2VjcDI1NmsxoQK1xa5wQynqfmTthWXz3mzZ904Sl4n10-v3gfB2um25h4RzbmFwwIN0Y3CCdl-DdWRwgnZf"
IP=$(curl ifconfig.io -4)

# GPU Acceleration Configuration for High-Performance RPC (RTX 4000 SFF Ada - 20GB VRAM)
ENABLE_GPU=true
PREFERRED_GPU_TYPE=CUDA
GPU_MAX_BATCH_SIZE=160000
GPU_MAX_MEMORY_USAGE=12884901888
GPU_MEMORY_FRACTION=0.5
GPU_HASH_WORKERS=16
GPU_SIGNATURE_WORKERS=16
GPU_TX_WORKERS=16
GPU_ENABLE_PIPELINING=true

# Hybrid Processing Configuration with AI Coordination
ENABLE_HYBRID_PROCESSING=true
GPU_THRESHOLD=1000
CPU_GPU_RATIO=0.85
ADAPTIVE_LOAD_BALANCING=true
PERFORMANCE_MONITORING=true
MAX_CPU_UTILIZATION=0.85
MAX_GPU_UTILIZATION=0.95
THROUGHPUT_TARGET=2000000

# Memory Management (RTX 4000 SFF Ada - 20GB Total)
MAX_MEMORY_USAGE=68719476736
GPU_MEMORY_RESERVATION=10737418240
AI_MEMORY_RESERVATION=8589934592
MEMORY_BUFFER=2147483648

# Performance Optimization for AI Sharing
GPU_DEVICE_COUNT=1
GPU_LOAD_BALANCE_STRATEGY=ai_optimized
AI_GPU_COORDINATION=true
ENABLE_CUDA_MPS=true

# CUDA Environment Configuration (Auto-activated by node-start.sh)
CUDA_PATH=/usr/local/cuda
CUDA_VISIBLE_DEVICES=0
LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/lib
PATH=/usr/local/cuda/bin:$PATH

# AI-Powered Load Balancing Configuration (vLLM + TinyLlama 1.1B)
ENABLE_AI_LOAD_BALANCING=true
LLM_ENDPOINT=http://localhost:8000/v1/completions
LLM_MODEL=TinyLlama/TinyLlama-1.1B-Chat-v1.0
LLM_TIMEOUT_SECONDS=2
AI_UPDATE_INTERVAL_MS=500
AI_HISTORY_SIZE=100
AI_LEARNING_RATE=0.15
AI_CONFIDENCE_THRESHOLD=0.75
AI_ENABLE_LEARNING=true
AI_ENABLE_PREDICTIONS=true
AI_FAST_MODE=true
VLLM_GPU_MEMORY_UTILIZATION=0.4
VLLM_MAX_MODEL_LEN=2048

VHOST=rpc1.splendor.org
